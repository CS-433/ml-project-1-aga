{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_own import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data -> use of the imported function made by the ML team (takes a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import load_csv_data\n",
    "\n",
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\".\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method allows us to take a specific feature out of X. My idea is to take a few of the interesting features out and concatenate them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_first_line(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        first_line = next(reader)\n",
    "        return first_line\n",
    "        \n",
    "def extract_feature(name):\n",
    "    filename = 'x_train.csv'\n",
    "    first_line = np.array(read_first_line(filename))\n",
    "    index = np.where(first_line == name)\n",
    "    ind = index[0].item()\n",
    "    return x_train[:, ind-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a quick method to see that our data is not \"clean\". There are a lot of nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of x features beeing not nan: 58177081\n",
      "Number of x features beeing nan: 47154254\n",
      "Number of y -1s: 299160\n",
      "Number of y 1s: 28975\n",
      "Number of y 0s: 0\n",
      "Number of y nan: 0\n"
     ]
    }
   ],
   "source": [
    "def caracteristics(x, y):\n",
    "    count = np.sum(~np.isnan(x))\n",
    "    print(\"Number of x features beeing not nan:\", count)\n",
    "    nan_count = np.sum(np.isnan(x))\n",
    "    print(\"Number of x features beeing nan:\", nan_count)\n",
    "    num_negatives = np.sum(y == -1)\n",
    "    print(\"Number of y -1s:\", num_negatives)\n",
    "    num_positives = np.sum(y == 1)\n",
    "    print(\"Number of y 1s:\", num_positives)\n",
    "    num_null = np.sum(y == 0)\n",
    "    print(\"Number of y 0s:\", num_null)\n",
    "    nan_count_y = np.sum(np.isnan(y))\n",
    "    print(\"Number of y nan:\", nan_count_y)\n",
    "\n",
    "#Here is for the specific feature \"_BMI5\"\n",
    "caracteristics(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to extract a few features and replace the lack of data with the mean (those features are taken from the website: https://medium.com/@alexteboul17/building-predictive-models-for-heart-disease-using-the-2015-behavioral-risk-factor-surveillance-b786368021ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_mean(x):\n",
    "    mean_value = np.nanmean(x)\n",
    "    x_new = x.copy()\n",
    "    x_new[np.isnan(x_new)] = mean_value\n",
    "    return x_new\n",
    "\n",
    "def replace_mode(x):\n",
    "    unique, counts = np.unique(x[~np.isnan(x)], return_counts=True)\n",
    "    mode_value = unique[np.argmax(counts)]\n",
    "    # Step 2: Replace NaN values with the mode\n",
    "    x[np.isnan(x)] = mode_value\n",
    "    return x\n",
    "\n",
    "\n",
    "################Body mass idex - continuous feature\n",
    "_BMI5 = extract_feature('_BMI5')\n",
    "_BMI5 = replace_mean(_BMI5)\n",
    "_BMI5, _BMI5_mean, _BMI5_std = standardize(_BMI5)\n",
    "\n",
    "\n",
    "################High blood pressure - categorical feature (1 = no, 2 = yes, 9 = missing)\n",
    "_RFHYPE5 = extract_feature('_RFHYPE5')\n",
    "_RFHYPE5[_RFHYPE5 == 9] = np.nan\n",
    "_RFHYPE5[_RFHYPE5 == 1] = 0\n",
    "_RFHYPE5[_RFHYPE5 == 2] = 1\n",
    "_RFHYPE5 = replace_mode(_RFHYPE5)\n",
    "\n",
    "################High cholesterol - categorical feature (1 = no, 2 = yes, 9 = missing)\n",
    "_RFCHOL = extract_feature('_RFCHOL')\n",
    "_RFCHOL[_RFCHOL == 9] = np.nan\n",
    "_RFCHOL[_RFCHOL == 1] = 0\n",
    "_RFCHOL[_RFCHOL == 2] = 1\n",
    "_RFCHOL = replace_mode(_RFCHOL)\n",
    "\n",
    "################Smoking status - categorical feature (1 = every day, 2 = some days, 3 = formerly, 4 = never, 9 = missing)\n",
    "_SMOKER3 = extract_feature('_SMOKER3')\n",
    "_SMOKER3[_SMOKER3 == 9] = np.nan\n",
    "_SMOKER3 = replace_mode(_SMOKER3)\n",
    "_SMOKER3, _SMOKER3_mean, _SMOKER3_std = standardize(_SMOKER3)\n",
    "\n",
    "################Has ever had a stroke  - categorical feature (1 = yes, 2 = no, 7 = don't know, 9 = missing)\n",
    "CVDSTRK3 = extract_feature('CVDSTRK3')\n",
    "CVDSTRK3[CVDSTRK3 == 9] = np.nan\n",
    "CVDSTRK3[CVDSTRK3 == 7] = np.nan\n",
    "CVDSTRK3[CVDSTRK3 == 2] = 0\n",
    "CVDSTRK3 = replace_mode(CVDSTRK3)\n",
    "\n",
    "################Cholesterol checked  - categorical feature (1 = within the last 5 years, 2 = more than 5 years ago, 3 = never, 9 = missing)\n",
    "_CHOLCHK = extract_feature('_CHOLCHK')\n",
    "_CHOLCHK[_CHOLCHK == 9] = np.nan\n",
    "_CHOLCHK = replace_mode(_CHOLCHK)\n",
    "_CHOLCHK,_ , _ = standardize(_CHOLCHK)\n",
    "\n",
    "################Has ever had diabetes  - categorical feature (1 = yes, 2 = yes*, 3 = no, 4 = no - pre-diabetes, 7 = don't know, 9 = missing)\n",
    "DIABETE3 = extract_feature('DIABETE3')\n",
    "DIABETE3[DIABETE3 == 9] = np.nan\n",
    "DIABETE3[DIABETE3 == 7] = np.nan\n",
    "DIABETE3[DIABETE3 == 3] = 0\n",
    "DIABETE3[DIABETE3 == 4] = 0\n",
    "DIABETE3[DIABETE3 == 2] = 1\n",
    "DIABETE3 = replace_mode(DIABETE3)\n",
    "\n",
    "################Physical activity index  - categorical feature (1 = highly active, 2 = active, 3 = insufficiently active, 4 = inactive, 9 = missing)\n",
    "_PACAT1 = extract_feature('_PACAT1')\n",
    "_PACAT1[_PACAT1 == 9] = np.nan\n",
    "_PACAT1 = replace_mode(_PACAT1)\n",
    "_PACAT1, _PACAT1_mean, _PACAT1_std = standardize(_PACAT1)\n",
    "\n",
    "################Total fruits consumed per day  - continuous feature (implied 2 dp)\n",
    "#_FRUTSUM = extract_feature('_FRUTSUM')\n",
    "\n",
    "################Total vegetables consumed per day  - continuous feature (implied 2 dp)\n",
    "#_VEGESUM = extract_feature('_VEGESUM')\n",
    "\n",
    "################Computed number of drinks of alcohol beverages per week  - continuous feature (99900 = missing)\n",
    "_DRNKWEK = extract_feature('_DRNKWEK')\n",
    "_DRNKWEK[_DRNKWEK == 99900] = np.nan\n",
    "_DRNKWEK = replace_mean(_DRNKWEK)\n",
    "_DRNKWEK, _DRNKWEK_mean, _DRNKWEK_std = standardize(_DRNKWEK)\n",
    "\n",
    "################Have any healthcare coverage  - categorical feature (1 = yes, 2 = no, 7 = don't know, 9 = missing)\n",
    "HLTHPLN1 = extract_feature('HLTHPLN1')\n",
    "HLTHPLN1[HLTHPLN1 == 9] = np.nan\n",
    "HLTHPLN1[HLTHPLN1 == 7] = np.nan\n",
    "HLTHPLN1[HLTHPLN1 == 2] = 0\n",
    "HLTHPLN1 = replace_mode(HLTHPLN1)\n",
    "\n",
    "################Could not see doctor because of cost  - categorical feature (1 = yes, 2 = no, 7 = don't know, 9 = missing)\n",
    "MEDCOST = extract_feature('MEDCOST')\n",
    "MEDCOST[MEDCOST == 9] = np.nan\n",
    "MEDCOST[MEDCOST == 7] = np.nan\n",
    "MEDCOST[MEDCOST == 2] = 0\n",
    "MEDCOST = replace_mode(MEDCOST)\n",
    "\n",
    "################General health status  - categorical feature (1 = excellent, 2 = very good, 3 = good, 4 = fair, 5 = poor, 7 = don't know, 9 = missing)\n",
    "GENHLTH = extract_feature('GENHLTH')\n",
    "GENHLTH[GENHLTH == 9] = np.nan\n",
    "GENHLTH[GENHLTH == 7] = np.nan\n",
    "GENHLTH = replace_mode(GENHLTH)\n",
    "GENHLTH, GENHLTH_mean, GENHLTH_std = standardize(GENHLTH)\n",
    "\n",
    "################Number of days mental health not good  - continuous feature (88 = none, 77 = don't know, 99 = refused)\n",
    "MENTHLTH = extract_feature('MENTHLTH')\n",
    "MENTHLTH[MENTHLTH == 88] = 0\n",
    "MENTHLTH[MENTHLTH == 77] = np.nan\n",
    "MENTHLTH[MENTHLTH == 99] = np.nan\n",
    "MENTHLTH = replace_mean(MENTHLTH)\n",
    "MENTHLTH, MENTHLTH_mean, MENTHLTH_std = standardize(MENTHLTH)\n",
    "\n",
    "################Number of days physical health not good  - continuous feature (88 = none, 77 = don't know, 99 = refused)\n",
    "PHYSHLTH = extract_feature('PHYSHLTH')\n",
    "PHYSHLTH[PHYSHLTH == 88] = 0\n",
    "PHYSHLTH[PHYSHLTH == 77] = np.nan\n",
    "PHYSHLTH[PHYSHLTH == 99] = np.nan\n",
    "PHYSHLTH = replace_mean(PHYSHLTH)\n",
    "PHYSHLTH, PHYSHLTH_mean, PHYSHLTH_std = standardize(PHYSHLTH)\n",
    "\n",
    "################Difficulty walking or climbing stairs - categorical feature (1 = yes, 2 = no, 7 = don't know, 9 = missing)\n",
    "DIFFWALK = extract_feature('DIFFWALK')\n",
    "DIFFWALK[DIFFWALK == 9] = np.nan\n",
    "DIFFWALK[DIFFWALK == 7] = np.nan\n",
    "DIFFWALK[DIFFWALK == 2] = 0\n",
    "DIFFWALK = replace_mode(DIFFWALK)\n",
    "\n",
    "################Sex - categorical feature (1 = male, 2 = female)\n",
    "SEX = extract_feature('SEX')\n",
    "SEX[SEX == 2] = 0\n",
    "SEX = replace_mode(SEX)\n",
    "\n",
    "################Age  - categorical feature (1 = 18-24, ... 13 = 80+, 14 = missing)\n",
    "_AGEG5YR = extract_feature('_AGEG5YR')\n",
    "_AGEG5YR[_AGEG5YR == 14] = np.nan\n",
    "_AGEG5YR = replace_mode(_AGEG5YR)\n",
    "_AGEG5YR, _AGEG5YR_mean, _AGEG5YR_std = standardize(_AGEG5YR)\n",
    "\n",
    "################Education  - categorical feature (1 = none, ... 6 = college grad, 9 = missing)\n",
    "EDUCA = extract_feature('EDUCA')\n",
    "EDUCA[EDUCA == 9] = np.nan\n",
    "EDUCA = replace_mode(EDUCA)\n",
    "EDUCA, EDUCA_mean, EDUCA_std = standardize(EDUCA)\n",
    "\n",
    "################Income level  - categorical feature (1 = low, ... 5 = high, 9 = missing)\n",
    "_INCOMG = extract_feature('_INCOMG')\n",
    "_INCOMG[_INCOMG == 9] = np.nan\n",
    "_INCOMG = replace_mode(_INCOMG)\n",
    "_INCOMG, _INCOMG_mean, _INCOMG_std = standardize(_INCOMG)\n",
    "\n",
    "#Here we stack the features together to have the our new X\n",
    "X = np.hstack((_BMI5.reshape(-1, 1), _RFHYPE5.reshape(-1, 1), _RFCHOL.reshape(-1, 1), _SMOKER3.reshape(-1, 1), CVDSTRK3.reshape(-1, 1), \n",
    "               _CHOLCHK.reshape(-1, 1), DIABETE3.reshape(-1, 1), _PACAT1.reshape(-1, 1), # _FRUTSUM.reshape(-1, 1), _VEGESUM.reshape(-1, 1), \n",
    "               _DRNKWEK.reshape(-1, 1), HLTHPLN1.reshape(-1, 1), MEDCOST.reshape(-1, 1), GENHLTH.reshape(-1, 1), MENTHLTH.reshape(-1, 1), PHYSHLTH.reshape(-1, 1), \n",
    "               DIFFWALK.reshape(-1, 1), SEX.reshape(-1, 1), _AGEG5YR.reshape(-1, 1), EDUCA.reshape(-1, 1), _INCOMG.reshape(-1, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of x features beeing not nan: 6234565\n",
      "Number of x features beeing nan: 0\n",
      "Number of y -1s: 299160\n",
      "Number of y 1s: 28975\n",
      "Number of y 0s: 0\n",
      "Number of y nan: 0\n"
     ]
    }
   ],
   "source": [
    "caracteristics(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count_per_column = np.sum(np.isnan(X), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_count_per_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 19)\n",
      "(328135,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of x features beeing not nan: 11368080\n",
      "Number of x features beeing nan: 0\n",
      "Number of y -1s: 299160\n",
      "Number of y 1s: 299160\n",
      "Number of y 0s: 0\n",
      "Number of y nan: 0\n"
     ]
    }
   ],
   "source": [
    "def balance_data(x, y):\n",
    "    #Balance the data by taking only a certain number of values in y=-1 s.t. the number of y=1 equals the number of y=-1\n",
    "    \n",
    "    indices_y_equals_1 = np.where(y == 1)[0]\n",
    "    indices_y_equals_minus_1 = np.where(y == -1)[0]\n",
    "    num_positives = np.sum(y == 1)\n",
    "    num_negatives = np.sum(y == -1)\n",
    "    selected_indices_neg = np.random.choice(indices_y_equals_minus_1, size=num_positives, replace=False)\n",
    "    \n",
    "    selected_indices = np.concatenate((selected_indices_neg, indices_y_equals_1))\n",
    "    selected_X = x[selected_indices]\n",
    "    selected_y = y[selected_indices]\n",
    "    \n",
    "    return selected_X, selected_y\n",
    "\n",
    "def balance_data_multiplier(X, y): \n",
    "    class_1 = X[y == 1]\n",
    "    class_minus_1 = X[y == -1]\n",
    "    count_class_1 = class_1.shape[0]\n",
    "    count_class_minus_1 = class_minus_1.shape[0]\n",
    "    num_to_duplicate = count_class_minus_1 - count_class_1\n",
    "    duplicated_samples = np.tile(class_1, (num_to_duplicate // count_class_1 + 1, 1))[:num_to_duplicate]\n",
    "    X_balanced = np.vstack((X, duplicated_samples))\n",
    "    y_balanced = np.hstack((y, np.ones(num_to_duplicate)))\n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "#print(y_train.shape)\n",
    "X_balanced, y_balanced = balance_data_multiplier(X, y_train)\n",
    "caracteristics(X_balanced, y_balanced)\n",
    "#X_balanced, y_balanced = balance_data(X, y_train)\n",
    "#caracteristics(X_balanced, y_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I just wanted to use the functions used in the exercise sessions. So I change from -1 to 0 for y negative so that I can use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change all the elements with -1 by 0\n",
    "y_train_working = y_balanced.copy()\n",
    "y_train_working[y_train_working == -1] = 0\n",
    "#Make y have the correct shape\n",
    "y_train_working = y_train_working.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into train and val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(538488, 19)\n",
      "(59832, 19)\n",
      "(538488, 1)\n",
      "(59832, 1)\n"
     ]
    }
   ],
   "source": [
    "def split_train_val(x, y, k_fold, k):\n",
    "    k_indices = build_k_indices(y, k_fold) \n",
    "    te_indice = k_indices[k]\n",
    "    tr_indice = k_indices[~(np.arange(k_indices.shape[0]) == k)]\n",
    "    tr_indice = tr_indice.reshape(-1)\n",
    "    y_te = y[te_indice]\n",
    "    y_tr = y[tr_indice]\n",
    "    x_te = x[te_indice]\n",
    "    x_tr = x[tr_indice]\n",
    "    return x_tr, x_te, y_tr, y_te\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = split_train_val(X_balanced, y_train_working, 10, 9)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of x features beeing not nan: 10231272\n",
      "Number of x features beeing nan: 0\n",
      "Number of y -1s: 0\n",
      "Number of y 1s: 269180\n",
      "Number of y 0s: 269308\n",
      "Number of y nan: 0\n",
      "(538488, 19)\n",
      "(59832, 19)\n",
      "(538488, 1)\n",
      "(59832, 1)\n"
     ]
    }
   ],
   "source": [
    "def drop_nan(X_train, Y_train, X_val, Y_val):\n",
    "    mask_train = ~np.isnan(X_train).any(axis=1)\n",
    "    X_train = X_train[mask_train]\n",
    "    Y_train = Y_train[mask_train]\n",
    "    \n",
    "    mask_val = ~np.isnan(X_val).any(axis=1)\n",
    "    X_val = X_val[mask_val]\n",
    "    Y_val = Y_val[mask_val]\n",
    "    return X_train, Y_train, X_val, Y_val\n",
    "\n",
    "#X_train, Y_train, X_val, Y_val = drop_nan(X_train, Y_train, X_val, Y_val)\n",
    "caracteristics(X_train, Y_train)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_gradient_descent(y, x, lambda_, gamma):\n",
    "    # init parameters\n",
    "    max_iter = 10000\n",
    "    threshold = 1e-7\n",
    "    losses = []\n",
    "\n",
    "    # build tx\n",
    "    tx = np.c_[np.ones((y.shape[0], 1)), x]\n",
    "    w = np.zeros((tx.shape[1], 1))\n",
    "    #print(tx)\n",
    "    #print(y)\n",
    "\n",
    "    # start the logistic regression\n",
    "    for iter in range(max_iter):\n",
    "        # get loss and update w.\n",
    "        loss, w = learning_by_gradient_descent_ridge(y, tx, w, gamma, lambda_)\n",
    "        # log info\n",
    "        if iter % 100 == 0:\n",
    "            print(\"Current iteration={i}, loss={l}\".format(i=iter, l=loss))\n",
    "        # converge criterion\n",
    "        losses.append(loss)\n",
    "        if len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < threshold:\n",
    "            break\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.6931471805599391\n",
      "Current iteration=100, loss=0.5118641615259965\n",
      "Current iteration=200, loss=0.49617194660608466\n",
      "Current iteration=300, loss=0.48977697328248704\n",
      "Current iteration=400, loss=0.48633679131459223\n",
      "Current iteration=500, loss=0.48425774041839453\n",
      "Current iteration=600, loss=0.48290684581378096\n",
      "Current iteration=700, loss=0.4819771136644689\n",
      "Current iteration=800, loss=0.4813046046449744\n",
      "Current iteration=900, loss=0.4807966464513939\n",
      "Current iteration=1000, loss=0.4803985753059114\n",
      "Current iteration=1100, loss=0.4800769179488843\n",
      "Current iteration=1200, loss=0.4798104361117697\n",
      "Current iteration=1300, loss=0.4795851807451848\n",
      "Current iteration=1400, loss=0.47939167761696955\n",
      "Current iteration=1500, loss=0.47922328170250456\n",
      "Current iteration=1600, loss=0.47907518966749096\n",
      "Current iteration=1700, loss=0.47894383193053486\n",
      "Current iteration=1800, loss=0.4788264887544607\n",
      "Current iteration=1900, loss=0.47872104157340994\n",
      "Current iteration=2000, loss=0.4786258078087124\n",
      "Current iteration=2100, loss=0.4785394284010662\n",
      "Current iteration=2200, loss=0.4784607893893554\n",
      "Current iteration=2300, loss=0.4783889659794298\n",
      "Current iteration=2400, loss=0.4783231818029156\n",
      "Current iteration=2500, loss=0.47826277866004024\n",
      "Current iteration=2600, loss=0.4782071936501261\n",
      "Current iteration=2700, loss=0.47815594161082925\n",
      "Current iteration=2800, loss=0.47810860144235906\n",
      "Current iteration=2900, loss=0.478064805322686\n",
      "Current iteration=3000, loss=0.4780242301069903\n",
      "Current iteration=3100, loss=0.47798659040010655\n",
      "Current iteration=3200, loss=0.4779516329261738\n",
      "Current iteration=3300, loss=0.4779191319151929\n",
      "Current iteration=3400, loss=0.4778888852945891\n",
      "Current iteration=3500, loss=0.4778607115236548\n",
      "Current iteration=3600, loss=0.4778344469454644\n",
      "Current iteration=3700, loss=0.4778099435583139\n",
      "Current iteration=3800, loss=0.4777870671295131\n",
      "Current iteration=3900, loss=0.47776569559024673\n",
      "Current iteration=4000, loss=0.47774571766250473\n",
      "Current iteration=4100, loss=0.4777270316786328\n",
      "Current iteration=4200, loss=0.4777095445615846\n",
      "Current iteration=4300, loss=0.4776931709398875\n",
      "Current iteration=4400, loss=0.4776778323760724\n",
      "Current iteration=4500, loss=0.4776634566911083\n",
      "Current iteration=4600, loss=0.4776499773704269\n",
      "Current iteration=4700, loss=0.4776373330395969\n",
      "Current iteration=4800, loss=0.4776254669997093\n",
      "Current iteration=4900, loss=0.47761432681417043\n",
      "Current iteration=5000, loss=0.4776038639399362\n",
      "[[-1.76984469]\n",
      " [ 0.0143856 ]\n",
      " [ 0.58026887]\n",
      " [ 0.60020169]\n",
      " [-0.16170341]\n",
      " [ 1.11455573]\n",
      " [-0.15362721]\n",
      " [ 0.33952425]\n",
      " [-0.04014361]\n",
      " [-0.03132185]\n",
      " [-0.13539887]\n",
      " [ 0.23604837]\n",
      " [ 0.50991184]\n",
      " [ 0.0477477 ]\n",
      " [ 0.04622207]\n",
      " [ 0.32057781]\n",
      " [ 0.76036395]\n",
      " [ 0.9025384 ]\n",
      " [-0.02587113]\n",
      " [-0.07437044]]\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.1\n",
    "lambda_ = 0.0001\n",
    "\n",
    "w, loss = logistic_regression_gradient_descent(Y_train, X_train, lambda_, gamma)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59832, 20)\n",
      "(20, 1)\n",
      "28250\n",
      "31582\n",
      "77.63738467709587\n"
     ]
    }
   ],
   "source": [
    "def prediction(tx_test, w):\n",
    "    compute = sigmoid(np.dot(tx_test, w))\n",
    "    y_test = (compute >= 0.5).astype(int)\n",
    "    return y_test\n",
    "#Now we test the result: % of well classified data\n",
    "def percentage_well_predicted(true_labels, predicted_labels):\n",
    "    # Check if both vectors have the same length\n",
    "    if len(true_labels) != len(predicted_labels):\n",
    "        raise ValueError(\"The two vectors must have the same length.\")\n",
    "    # Calculate the number of wrongly predicted points\n",
    "    num_right = np.sum(true_labels == predicted_labels)\n",
    "    # Calculate the percentage of wrongly predicted points\n",
    "    percentage_right = (num_right / len(true_labels)) * 100\n",
    "    return percentage_right\n",
    "tx = np.c_[np.ones((X_val.shape[0], 1)), X_val]\n",
    "print(tx.shape)\n",
    "print(w.shape)\n",
    "y_pred_test = prediction(tx, w)\n",
    "zero_count = np.sum(y_pred_test == 0)\n",
    "nonzero_count = np.sum(y_pred_test != 0)\n",
    "print(zero_count)\n",
    "print(nonzero_count)\n",
    "print(percentage_well_predicted(Y_val, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use our w to predict the results: we first format our x_test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_test(name):\n",
    "    filename = 'x_test.csv'\n",
    "    first_line = np.array(read_first_line(filename))\n",
    "    index = np.where(first_line == name)\n",
    "    ind = index[0].item()\n",
    "    return x_test[:, ind-1]\n",
    "\n",
    "################Body mass idex - continuous feature\n",
    "_BMI5 = extract_feature_test('_BMI5')\n",
    "_BMI5 = replace_mean(_BMI5)\n",
    "_BMI5, _BMI5_mean, _BMI5_std = standardize(_BMI5)\n",
    "\n",
    "\n",
    "################High blood pressure - categorical feature (1 = no, 2 = yes, 9 = missing)\n",
    "_RFHYPE5 = extract_feature_test('_RFHYPE5')\n",
    "_RFHYPE5[_RFHYPE5 == 9] = np.nan\n",
    "_RFHYPE5[_RFHYPE5 == 1] = 0\n",
    "_RFHYPE5[_RFHYPE5 == 2] = 1\n",
    "_RFHYPE5 = replace_mode(_RFHYPE5)\n",
    "\n",
    "################High cholesterol - categorical feature (1 = no, 2 = yes, 9 = missing)\n",
    "_RFCHOL = extract_feature_test('_RFCHOL')\n",
    "_RFCHOL[_RFCHOL == 9] = np.nan\n",
    "_RFCHOL[_RFCHOL == 1] = 0\n",
    "_RFCHOL[_RFCHOL == 2] = 1\n",
    "_RFCHOL = replace_mode(_RFCHOL)\n",
    "\n",
    "################Smoking status - categorical feature (1 = every day, 2 = some days, 3 = formerly, 4 = never, 9 = missing)\n",
    "_SMOKER3 = extract_feature_test('_SMOKER3')\n",
    "_SMOKER3[_SMOKER3 == 9] = np.nan\n",
    "_SMOKER3 = replace_mode(_SMOKER3)\n",
    "_SMOKER3, _SMOKER3_mean, _SMOKER3_std = standardize(_SMOKER3)\n",
    "\n",
    "################Has ever had a stroke  - categorical feature (1 = yes, 2 = no, 7 = don't know, 9 = missing)\n",
    "CVDSTRK3 = extract_feature_test('CVDSTRK3')\n",
    "CVDSTRK3[CVDSTRK3 == 9] = np.nan\n",
    "CVDSTRK3[CVDSTRK3 == 7] = np.nan\n",
    "CVDSTRK3[CVDSTRK3 == 2] = 0\n",
    "CVDSTRK3 = replace_mode(CVDSTRK3)\n",
    "\n",
    "################Cholesterol checked  - categorical feature (1 = within the last 5 years, 2 = more than 5 years ago, 3 = never, 9 = missing)\n",
    "_CHOLCHK = extract_feature_test('_CHOLCHK')\n",
    "_CHOLCHK[_CHOLCHK == 9] = np.nan\n",
    "_CHOLCHK = replace_mode(_CHOLCHK)\n",
    "_CHOLCHK,_ , _ = standardize(_CHOLCHK)\n",
    "\n",
    "################Has ever had diabetes  - categorical feature (1 = yes, 2 = yes*, 3 = no, 4 = no - pre-diabetes, 7 = don't know, 9 = missing)\n",
    "DIABETE3 = extract_feature_test('DIABETE3')\n",
    "DIABETE3[DIABETE3 == 9] = np.nan\n",
    "DIABETE3[DIABETE3 == 7] = np.nan\n",
    "DIABETE3[DIABETE3 == 3] = 0\n",
    "DIABETE3[DIABETE3 == 4] = 0\n",
    "DIABETE3[DIABETE3 == 2] = 1\n",
    "DIABETE3 = replace_mode(DIABETE3)\n",
    "\n",
    "################Physical activity index  - categorical feature (1 = highly active, 2 = active, 3 = insufficiently active, 4 = inactive, 9 = missing)\n",
    "_PACAT1 = extract_feature_test('_PACAT1')\n",
    "_PACAT1[_PACAT1 == 9] = np.nan\n",
    "_PACAT1 = replace_mode(_PACAT1)\n",
    "_PACAT1, _PACAT1_mean, _PACAT1_std = standardize(_PACAT1)\n",
    "\n",
    "################Total fruits consumed per day  - continuous feature (implied 2 dp)\n",
    "#_FRUTSUM = extract_feature('_FRUTSUM')\n",
    "\n",
    "################Total vegetables consumed per day  - continuous feature (implied 2 dp)\n",
    "#_VEGESUM = extract_feature('_VEGESUM')\n",
    "\n",
    "################Computed number of drinks of alcohol beverages per week  - continuous feature (99900 = missing)\n",
    "_DRNKWEK = extract_feature_test('_DRNKWEK')\n",
    "_DRNKWEK[_DRNKWEK == 99900] = np.nan\n",
    "_DRNKWEK = replace_mean(_DRNKWEK)\n",
    "_DRNKWEK, _DRNKWEK_mean, _DRNKWEK_std = standardize(_DRNKWEK)\n",
    "\n",
    "################Have any healthcare coverage  - categorical feature (1 = yes, 2 = no, 7 = don't know, 9 = missing)\n",
    "HLTHPLN1 = extract_feature_test('HLTHPLN1')\n",
    "HLTHPLN1[HLTHPLN1 == 9] = np.nan\n",
    "HLTHPLN1[HLTHPLN1 == 7] = np.nan\n",
    "HLTHPLN1[HLTHPLN1 == 2] = 0\n",
    "HLTHPLN1 = replace_mode(HLTHPLN1)\n",
    "\n",
    "################Could not see doctor because of cost  - categorical feature (1 = yes, 2 = no, 7 = don't know, 9 = missing)\n",
    "MEDCOST = extract_feature_test('MEDCOST')\n",
    "MEDCOST[MEDCOST == 9] = np.nan\n",
    "MEDCOST[MEDCOST == 7] = np.nan\n",
    "MEDCOST[MEDCOST == 2] = 0\n",
    "MEDCOST = replace_mode(MEDCOST)\n",
    "\n",
    "################General health status  - categorical feature (1 = excellent, 2 = very good, 3 = good, 4 = fair, 5 = poor, 7 = don't know, 9 = missing)\n",
    "GENHLTH = extract_feature_test('GENHLTH')\n",
    "GENHLTH[GENHLTH == 9] = np.nan\n",
    "GENHLTH[GENHLTH == 7] = np.nan\n",
    "GENHLTH = replace_mode(GENHLTH)\n",
    "GENHLTH, GENHLTH_mean, GENHLTH_std = standardize(GENHLTH)\n",
    "\n",
    "################Number of days mental health not good  - continuous feature (88 = none, 77 = don't know, 99 = refused)\n",
    "MENTHLTH = extract_feature_test('MENTHLTH')\n",
    "MENTHLTH[MENTHLTH == 88] = 0\n",
    "MENTHLTH[MENTHLTH == 77] = np.nan\n",
    "MENTHLTH[MENTHLTH == 99] = np.nan\n",
    "MENTHLTH = replace_mean(MENTHLTH)\n",
    "MENTHLTH, MENTHLTH_mean, MENTHLTH_std = standardize(MENTHLTH)\n",
    "\n",
    "################Number of days physical health not good  - continuous feature (88 = none, 77 = don't know, 99 = refused)\n",
    "PHYSHLTH = extract_feature_test('PHYSHLTH')\n",
    "PHYSHLTH[PHYSHLTH == 88] = 0\n",
    "PHYSHLTH[PHYSHLTH == 77] = np.nan\n",
    "PHYSHLTH[PHYSHLTH == 99] = np.nan\n",
    "PHYSHLTH = replace_mean(PHYSHLTH)\n",
    "PHYSHLTH, PHYSHLTH_mean, PHYSHLTH_std = standardize(PHYSHLTH)\n",
    "\n",
    "################Difficulty walking or climbing stairs - categorical feature (1 = yes, 2 = no, 7 = don't know, 9 = missing)\n",
    "DIFFWALK = extract_feature_test('DIFFWALK')\n",
    "DIFFWALK[DIFFWALK == 9] = np.nan\n",
    "DIFFWALK[DIFFWALK == 7] = np.nan\n",
    "DIFFWALK[DIFFWALK == 2] = 0\n",
    "DIFFWALK = replace_mode(DIFFWALK)\n",
    "\n",
    "################Sex - categorical feature (1 = male, 2 = female)\n",
    "SEX = extract_feature_test('SEX')\n",
    "SEX[SEX == 2] = 0\n",
    "SEX = replace_mode(SEX)\n",
    "\n",
    "################Age  - categorical feature (1 = 18-24, ... 13 = 80+, 14 = missing)\n",
    "_AGEG5YR = extract_feature_test('_AGEG5YR')\n",
    "_AGEG5YR[_AGEG5YR == 14] = np.nan\n",
    "_AGEG5YR = replace_mode(_AGEG5YR)\n",
    "_AGEG5YR, _AGEG5YR_mean, _AGEG5YR_std = standardize(_AGEG5YR)\n",
    "\n",
    "################Education  - categorical feature (1 = none, ... 6 = college grad, 9 = missing)\n",
    "EDUCA = extract_feature_test('EDUCA')\n",
    "EDUCA[EDUCA == 9] = np.nan\n",
    "EDUCA = replace_mode(EDUCA)\n",
    "EDUCA, EDUCA_mean, EDUCA_std = standardize(EDUCA)\n",
    "\n",
    "################Income level  - categorical feature (1 = low, ... 5 = high, 9 = missing)\n",
    "_INCOMG = extract_feature_test('_INCOMG')\n",
    "_INCOMG[_INCOMG == 9] = np.nan\n",
    "_INCOMG = replace_mode(_INCOMG)\n",
    "_INCOMG, _INCOMG_mean, _INCOMG_std = standardize(_INCOMG)\n",
    "\n",
    "#Here we stack the features together to have the our new X\n",
    "X_test = np.hstack((_BMI5.reshape(-1, 1), _RFHYPE5.reshape(-1, 1), _RFCHOL.reshape(-1, 1), _SMOKER3.reshape(-1, 1), CVDSTRK3.reshape(-1, 1), \n",
    "               _CHOLCHK.reshape(-1, 1), DIABETE3.reshape(-1, 1), _PACAT1.reshape(-1, 1), # _FRUTSUM.reshape(-1, 1), _VEGESUM.reshape(-1, 1), \n",
    "               _DRNKWEK.reshape(-1, 1), HLTHPLN1.reshape(-1, 1), MEDCOST.reshape(-1, 1), GENHLTH.reshape(-1, 1), MENTHLTH.reshape(-1, 1), PHYSHLTH.reshape(-1, 1), \n",
    "               DIFFWALK.reshape(-1, 1), SEX.reshape(-1, 1), _AGEG5YR.reshape(-1, 1), EDUCA.reshape(-1, 1), _INCOMG.reshape(-1, 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we actually want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(tx_test, w):\n",
    "    compute = sigmoid(np.dot(tx_test, w))\n",
    "    y_test = (compute >= 0.5).astype(int)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -9.09070615e-01  1.00000000e+00 ...  1.54082763e+00\n",
      "   1.04300780e+00  7.41110652e-01]\n",
      " [ 1.00000000e+00 -9.67684643e-01  0.00000000e+00 ... -1.96329906e+00\n",
      "   1.04300780e+00  7.41110652e-01]\n",
      " [ 1.00000000e+00  1.68842320e-15  1.00000000e+00 ...  6.64795955e-01\n",
      "   1.04300780e+00  7.41110652e-01]\n",
      " ...\n",
      " [ 1.00000000e+00 -5.13029881e-01  0.00000000e+00 ...  1.54082763e+00\n",
      "   1.04300780e+00 -6.82577255e-01]\n",
      " [ 1.00000000e+00 -6.41347079e-01  0.00000000e+00 ...  1.54082763e+00\n",
      "   8.50664592e-02  7.41110652e-01]\n",
      " [ 1.00000000e+00  2.24024530e+00  1.00000000e+00 ... -5.03246272e-01\n",
      "   8.50664592e-02  7.41110652e-01]]\n",
      "[[-1.76984469]\n",
      " [ 0.0143856 ]\n",
      " [ 0.58026887]\n",
      " [ 0.60020169]\n",
      " [-0.16170341]\n",
      " [ 1.11455573]\n",
      " [-0.15362721]\n",
      " [ 0.33952425]\n",
      " [-0.04014361]\n",
      " [-0.03132185]\n",
      " [-0.13539887]\n",
      " [ 0.23604837]\n",
      " [ 0.50991184]\n",
      " [ 0.0477477 ]\n",
      " [ 0.04622207]\n",
      " [ 0.32057781]\n",
      " [ 0.76036395]\n",
      " [ 0.9025384 ]\n",
      " [-0.02587113]\n",
      " [-0.07437044]]\n",
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "33043\n",
      "76336\n"
     ]
    }
   ],
   "source": [
    "tx_test = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "print(tx_test)\n",
    "print(w)\n",
    "y_pred = prediction(tx_test, w)\n",
    "print(y_pred)\n",
    "nonzero_count = np.sum(y_pred != 0)\n",
    "zero_count = np.sum(y_pred == 0)\n",
    "print(nonzero_count)\n",
    "print(zero_count)\n",
    "y_pred[y_pred == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import create_csv_submission\n",
    "create_csv_submission(test_ids, y_pred, \"Submission_test_github\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
