{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_own import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data -> use of the imported function made by the ML team (takes a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import load_csv_data\n",
    "\n",
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"./dataset\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a quick method to see that our data is not \"clean\". There are a lot of nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caracteristics(x, y):\n",
    "    count = np.sum(~np.isnan(x))\n",
    "    print(\"Number of x features being not nan:\", count)\n",
    "    nan_count = np.sum(np.isnan(x))\n",
    "    print(\"Number of x features being nan:\", nan_count)\n",
    "    num_negatives = np.sum(y == -1)\n",
    "    print(\"Number of y -1s:\", num_negatives)\n",
    "    num_positives = np.sum(y == 1)\n",
    "    print(\"Number of y 1s:\", num_positives)\n",
    "    num_null = np.sum(y == 0)\n",
    "    print(\"Number of y 0s:\", num_null)\n",
    "    nan_count_y = np.sum(np.isnan(y))\n",
    "    print(\"Number of y nan:\", nan_count_y)\n",
    "\n",
    "#Here is for the specific feature \"_BMI5\"\n",
    "caracteristics(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to extract a few features and replace the lack of data with the mean (those features are taken from the website: https://medium.com/@alexteboul17/building-predictive-models-for-heart-disease-using-the-2015-behavioral-risk-factor-surveillance-b786368021ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test = make_data('./dataset/x_train.csv', './dataset/x_test.csv', x_train, x_test, y_train, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caracteristics(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For undesampling fully\n",
    "#X_train_balanced, Y_train_balanced = undersampling(X_train, Y_train)\n",
    "\n",
    "# For oversampling fully\n",
    "#X_train_balanced, Y_train_balanced = oversampling(X_train, Y_train)\n",
    "\n",
    "# For undersampling and oversampling at the same time\n",
    "# ratio_majority is the desired factor of reduction of majority samples for undersampling\n",
    "# ratio_majority_to_minority is the desired ratio of majority to minority samples for oversampling\n",
    "X_train_balanced, Y_train_balanced = undersampling_oversampling(X_train, Y_train, ratio_majority=1, ratio_majority_to_minority=2)\n",
    "\n",
    "caracteristics(X_train_balanced, Y_train_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_gradient_descent(y_train, x_train, y_val, x_val, lambda1, lambda2, gamma):\n",
    "    # init parameters\n",
    "    max_iter = 10000\n",
    "    threshold = 1e-8\n",
    "    losses = []\n",
    "    losses_val = []\n",
    "\n",
    "    # build tx_train\n",
    "    tx_train = np.c_[np.ones((y_train.shape[0], 1)), x_train]\n",
    "    w = np.zeros((tx_train.shape[1], 1))\n",
    "    #print(tx_train)\n",
    "    #print(y_train)\n",
    "    tx_val = np.c_[np.ones((y_val.shape[0], 1)), x_val]\n",
    "\n",
    "    # start the logistic regression\n",
    "    for iter in range(max_iter):\n",
    "        # get loss and update w.\n",
    "        loss, w = learning_by_gradient_descent_ridge_lasso(y_train, tx_train, w, gamma, lambda1, lambda2)\n",
    "        loss_val = calculate_loss(y_val, tx_val, w, lambda1=lambda1, lambda2=lambda2)\n",
    "        # log info\n",
    "        if iter % 100 == 0:\n",
    "            print(\"Current iteration={i}, loss={l}\".format(i=iter, l=loss))\n",
    "        # converge criterion\n",
    "        losses.append(loss)\n",
    "        losses_val.append(loss_val)\n",
    "        #Â NB: Stopping criterion based on val loss now\n",
    "        if len(losses_val) > 1 and np.abs(losses_val[-1] - losses_val[-2]) < threshold:\n",
    "            print('finished')\n",
    "            break\n",
    "    return w, loss, losses, losses_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gamma = 0.05\n",
    "lambda1 = 0\n",
    "lambda2 = 0\n",
    "\n",
    "w, loss, losses, losses_val = logistic_regression_gradient_descent(Y_train_balanced, X_train_balanced, Y_val, X_val, lambda1, lambda2, gamma)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the train and val losses\n",
    "plt.plot(losses, label='train')\n",
    "plt.plot(losses_val, label='val')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prediction(tx_test, w):\n",
    "    compute = sigmoid(np.dot(tx_test, w))\n",
    "    y_test = (compute >= 0.5).astype(int)\n",
    "    return y_test\n",
    "#Now we test the result: % of well classified data\n",
    "def percentage_well_predicted(true_labels, predicted_labels):\n",
    "    # Check if both vectors have the same length\n",
    "    if len(true_labels) != len(predicted_labels):\n",
    "        raise ValueError(\"The two vectors must have the same length.\")\n",
    "    # Calculate the number of wrongly predicted points\n",
    "    num_right = np.sum(true_labels == predicted_labels)\n",
    "    # Calculate the percentage of wrongly predicted points\n",
    "    percentage_right = (num_right / len(true_labels)) * 100\n",
    "    return percentage_right\n",
    "tx_val = np.c_[np.ones((X_val.shape[0], 1)), X_val]\n",
    "print(tx_val.shape)\n",
    "print(w.shape)\n",
    "y_pred_test = prediction(tx_val, w)\n",
    "zero_count = np.sum(y_pred_test == 0)\n",
    "nonzero_count = np.sum(y_pred_test != 0)\n",
    "print(zero_count)\n",
    "print(nonzero_count)\n",
    "print(percentage_well_predicted(Y_val, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_pred, y_true):\n",
    "    tp = np.sum(y_pred[y_true == 1] == 1)\n",
    "    fp = np.sum(y_pred[y_true == 0] == 1)\n",
    "    fn = np.sum(y_pred[y_true == 1] == 0)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "print(f1(y_pred_test, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_pred, y_true):\n",
    "    tp = np.sum(y_pred[y_true == 1] == 1)\n",
    "    fp = np.sum(y_pred[y_true == 0] == 1)\n",
    "    fn = np.sum(y_pred[y_true == 1] == 0)\n",
    "    tn = np.sum(y_pred[y_true == 0] == 0)\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "tp, fp, fn, tn = confusion_matrix(y_pred_test, Y_val)\n",
    "print(tp)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_val, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use our w to predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(tx_test, w):\n",
    "    compute = sigmoid(np.dot(tx_test, w))\n",
    "    y_test = (compute >= 0.7).astype(int)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_test = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "print(tx_test)\n",
    "print(w)\n",
    "y_pred = prediction(tx_test, w)\n",
    "print(y_pred)\n",
    "nonzero_count = np.sum(y_pred != 0)\n",
    "zero_count = np.sum(y_pred == 0)\n",
    "print(nonzero_count)\n",
    "print(zero_count)\n",
    "y_pred[y_pred == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import create_csv_submission\n",
    "create_csv_submission(test_ids, y_pred, \"Submission_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
