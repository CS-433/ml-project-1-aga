{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_create_data import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import the data here\n",
    "from helpers import load_csv_data\n",
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"./dataset\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we extract the wanted features, and take care of the nans\n",
    "X_train, Y_train, X_val, Y_val, X_test = make_data('./dataset/x_train.csv', './dataset/x_test.csv', x_train, x_test, y_train, replace=False, onehotecode = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We undersample by dropping half of the data points in the majortity class\n",
    "#We oversample by multiplying the minority class s.t. the number of data points is half the number of datapoints of majority class)\n",
    "X_train_balanced, Y_train_balanced = undersampling_oversampling(X_train, Y_train, ratio_majority=0.5, ratio_majority_to_minority=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gamma = 0.05 was giving us good results while converging in acceptable time\n",
    "gamma = 0.05\n",
    "max_iter = 10000\n",
    "\n",
    "#We add a column of  ones before training\n",
    "tx_train = np.c_[np.ones((Y_train_balanced.shape[0], 1)), X_train_balanced]\n",
    "#Reshape y_train form (#points,1) to (#points,) in order to use the implemented logistic regression function\n",
    "yx_train = Y_train_balanced.reshape(-1)\n",
    "#Create a new w in order to match the number of sected feature and has shape (1 + #features, )\n",
    "w_reg = np.zeros((tx_train.shape[1], 1)).reshape(-1)\n",
    "#Train model (-> our train set) using logistic regression\n",
    "w, loss = logistic_regression(yx_train, tx_train, w_reg, max_iter, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.56581718e+00  3.26037763e-02  2.71478500e-01  3.04059991e-01\n",
      " -1.68470451e-01  2.09970840e-01 -9.96740449e-02  1.00003362e-01\n",
      " -4.56104921e-02 -5.42285509e-02  5.69149390e-03  7.55699438e-02\n",
      "  5.27262183e-01  2.77692224e-02  1.92281179e-02  1.17660907e-01\n",
      "  3.95530408e-01  8.39177315e-01  6.61353076e-04 -8.31970944e-02]\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.74305915338432\n",
      "F1:  0.4116851501217203\n"
     ]
    }
   ],
   "source": [
    "#Here we compute the accuracy and the f1 score for the validation set\n",
    "tx_val = np.c_[np.ones((X_val.shape[0], 1)), X_val]\n",
    "#y_pred_test are the predicted labels for the validation set\n",
    "y_pred_test = prediction(tx_val, w)\n",
    "Y_val = Y_val.reshape(-1)\n",
    "print('Accuracy:', compute_accuracy(Y_val, y_pred_test))\n",
    "print('F1: ', f1(y_pred_test, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we actually make the prediction for the test set\n",
    "tx_test = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "y_pred = prediction(tx_test, w)\n",
    "y_pred[y_pred == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import create_csv_submission\n",
    "create_csv_submission(test_ids, y_pred, \"Submission_06.10.2024_16_12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
